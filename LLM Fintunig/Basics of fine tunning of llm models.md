***Fine Tuning***
Fine tunning is a concept of giving the llm model specific exmaples(datasets)to help learn the task betters.

***Some Key  Terms In Fine Tuning***

- **[[Backpropegation]]**: 
	- It is method used to train AI models, similar to how you learn from your mistakes,The model makes a guess,sees how far off it was and then adjust it guess for next time:
	- First, the network makes a guess (prediction). Then, we compare it to the actual answer (target).
	- Backpropagation calculates how much the guess was off (the error).
	- It then adjusts the network’s connections (weights) to reduce this error.
	- This process repeats for many examples until the network gets better at predicting.
-  [[LLM Parameters]]	
	- Imagine you’re trying to learn how to play a video game. At first, you might not know which buttons make your character jump or run. But as you play more, you learn these controls. In this analogy, your brain is adjusting its “parameters” to understand the game better.
	- In an LLM, parameters work in a similar way. They start off not knowing much about language. But as they “see” more examples of sentences and words, they adjust their parameters to understand and predict language better.
- [[Weights]
	- In an LLM, each input (like a word in a sentence) is associated with a weight. The model learns these weights during training. If a word has a high weight, it means that the word is very influential in determining the output of the model. If a word has a low weight, it’s less influential.

